{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment # https://github.com/jiaaro/pydub\n",
    "import gc\n",
    "import speech_recognition as sr\n",
    "from pydub.silence import split_on_silence\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing video and audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 convert video to audio (wav) files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 load video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lec_3_vid = AudioSegment.from_file(\"data/video/20200120-102822-008.mp4\")\n",
    "lec_5_vid = AudioSegment.from_file(\"data/video/20200127-102817-008.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20200120-102822-008.mp4', '20200127-102817-008.mp4']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"data/video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_dict = {f\"vid_{i+1}\" : os.listdir(\"data/video\")[i] for i in range(len(os.listdir(\"data/video\")))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vid_1': '20200120-102822-008.mp4', 'vid_2': '20200127-102817-008.mp4'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Convert video to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='data/audio/vid_2.wav'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lec_3_vid.export(\"data/audio/vid_1.wav\", format=\"wav\")\n",
    "lec_5_vid.export(\"data/audio/vid_2.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lec_3_vid, lec_5_vid\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Convert audio to text [1] [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Chunk audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_chunker(audio_files_dir, op_dir, chunk_size=5000):\n",
    "    \"\"\"\n",
    "    Takes in list of audio files\n",
    "    directories and prepares \n",
    "    audio segment to process into\n",
    "    audio chunks. Output of chunk\n",
    "    will be under subdirectory of\n",
    "    video title under op_dir/vid_n\n",
    "    where n is count of video.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    audio_files_dir : list\n",
    "        list of audio files to\n",
    "        create chunks of.\n",
    "    \n",
    "    op_dir : str\n",
    "        output directory to \n",
    "        store chunks.\n",
    "    \n",
    "    chunk_size : int\n",
    "        size of audio chunks in ms,\n",
    "        default 5000 as Google API\n",
    "        supports 5 seconds.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> audio_files = [\"data/audio/vid_1.wav\", \"data/audio/vid_2.wav\"]\n",
    "    >>> audio_chunker(audio_files, \"data/audio_chunks/\")\n",
    "    \"\"\"\n",
    "    audio_segs = [AudioSegment.from_wav(audio_files[0]),\n",
    "                  AudioSegment.from_wav(audio_files[1])]\n",
    "    \n",
    "    for count, audio_seg in enumerate(audio_segs):\n",
    "        \n",
    "        print(f\"Prcoessing audio file {count+1}/{len(audio_segs)}...\")\n",
    "        len_audio = len(audio_seg) # length of audio segment\n",
    "        n_chunks = len_audio//chunk_size # calculate chink size\n",
    "        \n",
    "        storage_dir = f\"{op_dir}vid_{count+1}/\"\n",
    "        os.mkdir(storage_dir) # create storage dir\n",
    "        \n",
    "        # create chunks and export to directory\n",
    "        for i in range(n_chunks):\n",
    "            \n",
    "            if i == 0:\n",
    "                start = 0\n",
    "                end = chunk_size\n",
    "            else:\n",
    "                start = end\n",
    "                end = start + chunk_size\n",
    "\n",
    "            chunk = audio_seg[start:end]\n",
    "            \n",
    "            chunk.export(f\"{storage_dir}chunk_{i}.wav\", format=\"wav\")\n",
    "    \n",
    "    print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prcoessing audio file 1/2...\n",
      "Prcoessing audio file 2/2...\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "audio_files = [\"data/audio/vid_1.wav\", \"data/audio/vid_2.wav\"]\n",
    "audio_chunker(audio_files, \"data/audio_chunks/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Speech recognition and saving to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_chunk_to_text(audio_chunks_dir, op_dir, max_text_len=10000):\n",
    "    \"\"\"\n",
    "    Takes in audio chunks directory\n",
    "    and performs speech recognition\n",
    "    on each chunk and stores text\n",
    "    to vid_n.txt where n is the \n",
    "    count of the video.\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    audio_chunks_dir : str\n",
    "        parent directory where audio \n",
    "        of where audio chunks for \n",
    "        video_n's are located.\n",
    "    \n",
    "    op_dir : str\n",
    "        text storage directory,\n",
    "        will be in the form video_n.txt,\n",
    "        where n is the count of video.\n",
    "        \n",
    "    max_text_len : \n",
    "        will stop the speech recognition\n",
    "        after if exceeds max_character length.\n",
    "        \n",
    "    Returns:\n",
    "    ---------\n",
    "    None\n",
    "    \"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    audio_chunk_videos = os.listdir(audio_chunks_dir)\n",
    "    for count, video in enumerate(audio_chunk_videos):\n",
    "        audio_chunks = os.listdir(audio_chunks_dir + video)\n",
    "        print(f\"Processing video: {count+1}/{len(audio_chunk_videos)}\")\n",
    "        print(\"---\"*12)\n",
    "        output_text = \"\"\n",
    "        step_counter = 0\n",
    "        \n",
    "        for i in range(len(audio_chunk_files)):\n",
    "            if i%5 == 0:\n",
    "                print(f\"Step {step_counter+1}\")\n",
    "                print(f\"Char length: {len(output_text)}\")\n",
    "                print(f\"Processing chunk: {i+1}/{len(audio_chunks)}...\")\n",
    "                step_counter += 1\n",
    "            \n",
    "            aud_file = f\"{audio_chunks_dir}{video}/chunk_{i}.wav\"\n",
    "            with sr.AudioFile(aud_file) as source:\n",
    "                r.adjust_for_ambient_noise(source)\n",
    "                audio = r.listen(source)\n",
    "            try:\n",
    "                text = r.recognize_google(audio)\n",
    "                output_text += text + \" \"\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            if len(output_text) > max_text_len:\n",
    "                break\n",
    "\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        text_file = open(f\"{op_dir}transcribed_{video}.txt\", \"w+\")\n",
    "        text_file.write(output_text)\n",
    "        text_file.close()\n",
    "        print(f\"Process complete! {i+1}/{len(audio_chunks)} converted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: 1/2\n",
      "------------------------------------\n",
      "Step 1\n",
      "Char length: 0\n",
      "Processing chunk: 1/1018...\n",
      "Step 2\n",
      "Char length: 195\n",
      "Processing chunk: 6/1018...\n",
      "Step 3\n",
      "Char length: 351\n",
      "Processing chunk: 11/1018...\n",
      "Step 4\n",
      "Char length: 486\n",
      "Processing chunk: 16/1018...\n",
      "Step 5\n",
      "Char length: 641\n",
      "Processing chunk: 21/1018...\n",
      "Step 6\n",
      "Char length: 753\n",
      "Processing chunk: 26/1018...\n",
      "Step 7\n",
      "Char length: 887\n",
      "Processing chunk: 31/1018...\n",
      "Step 8\n",
      "Char length: 1052\n",
      "Processing chunk: 36/1018...\n",
      "Step 9\n",
      "Char length: 1168\n",
      "Processing chunk: 41/1018...\n",
      "Step 10\n",
      "Char length: 1351\n",
      "Processing chunk: 46/1018...\n",
      "Step 11\n",
      "Char length: 1483\n",
      "Processing chunk: 51/1018...\n",
      "Step 12\n",
      "Char length: 1683\n",
      "Processing chunk: 56/1018...\n",
      "Step 13\n",
      "Char length: 1841\n",
      "Processing chunk: 61/1018...\n",
      "Step 14\n",
      "Char length: 2023\n",
      "Processing chunk: 66/1018...\n",
      "Step 15\n",
      "Char length: 2182\n",
      "Processing chunk: 71/1018...\n",
      "Step 16\n",
      "Char length: 2381\n",
      "Processing chunk: 76/1018...\n",
      "Step 17\n",
      "Char length: 2596\n",
      "Processing chunk: 81/1018...\n",
      "Step 18\n",
      "Char length: 2750\n",
      "Processing chunk: 86/1018...\n",
      "Step 19\n",
      "Char length: 3014\n",
      "Processing chunk: 91/1018...\n",
      "Step 20\n",
      "Char length: 3171\n",
      "Processing chunk: 96/1018...\n",
      "Step 21\n",
      "Char length: 3357\n",
      "Processing chunk: 101/1018...\n",
      "Step 22\n",
      "Char length: 3545\n",
      "Processing chunk: 106/1018...\n",
      "Step 23\n",
      "Char length: 3771\n",
      "Processing chunk: 111/1018...\n",
      "Step 24\n",
      "Char length: 3840\n",
      "Processing chunk: 116/1018...\n",
      "Step 25\n",
      "Char length: 3992\n",
      "Processing chunk: 121/1018...\n",
      "Step 26\n",
      "Char length: 4167\n",
      "Processing chunk: 126/1018...\n",
      "Step 27\n",
      "Char length: 4264\n",
      "Processing chunk: 131/1018...\n",
      "Step 28\n",
      "Char length: 4467\n",
      "Processing chunk: 136/1018...\n",
      "Step 29\n",
      "Char length: 4534\n",
      "Processing chunk: 141/1018...\n",
      "Step 30\n",
      "Char length: 4677\n",
      "Processing chunk: 146/1018...\n",
      "Step 31\n",
      "Char length: 4830\n",
      "Processing chunk: 151/1018...\n",
      "Step 32\n",
      "Char length: 4895\n",
      "Processing chunk: 156/1018...\n",
      "Step 33\n",
      "Char length: 5052\n",
      "Processing chunk: 161/1018...\n",
      "Step 34\n",
      "Char length: 5301\n",
      "Processing chunk: 166/1018...\n",
      "Step 35\n",
      "Char length: 5551\n",
      "Processing chunk: 171/1018...\n",
      "Step 36\n",
      "Char length: 5690\n",
      "Processing chunk: 176/1018...\n",
      "Step 37\n",
      "Char length: 5944\n",
      "Processing chunk: 181/1018...\n",
      "Step 38\n",
      "Char length: 6200\n",
      "Processing chunk: 186/1018...\n",
      "Step 39\n",
      "Char length: 6277\n",
      "Processing chunk: 191/1018...\n",
      "Step 40\n",
      "Char length: 6446\n",
      "Processing chunk: 196/1018...\n",
      "Step 41\n",
      "Char length: 6606\n",
      "Processing chunk: 201/1018...\n",
      "Step 42\n",
      "Char length: 6790\n",
      "Processing chunk: 206/1018...\n",
      "Step 43\n",
      "Char length: 6919\n",
      "Processing chunk: 211/1018...\n",
      "Step 44\n",
      "Char length: 7133\n",
      "Processing chunk: 216/1018...\n",
      "Step 45\n",
      "Char length: 7336\n",
      "Processing chunk: 221/1018...\n",
      "Step 46\n",
      "Char length: 7669\n",
      "Processing chunk: 226/1018...\n",
      "Step 47\n",
      "Char length: 7975\n",
      "Processing chunk: 231/1018...\n",
      "Step 48\n",
      "Char length: 8124\n",
      "Processing chunk: 236/1018...\n",
      "Step 49\n",
      "Char length: 8345\n",
      "Processing chunk: 241/1018...\n",
      "Step 50\n",
      "Char length: 8529\n",
      "Processing chunk: 246/1018...\n",
      "Step 51\n",
      "Char length: 8697\n",
      "Processing chunk: 251/1018...\n",
      "Step 52\n",
      "Char length: 8946\n",
      "Processing chunk: 256/1018...\n",
      "Step 53\n",
      "Char length: 9122\n",
      "Processing chunk: 261/1018...\n",
      "Step 54\n",
      "Char length: 9272\n",
      "Processing chunk: 266/1018...\n",
      "Step 55\n",
      "Char length: 9513\n",
      "Processing chunk: 271/1018...\n",
      "Step 56\n",
      "Char length: 9757\n",
      "Processing chunk: 276/1018...\n",
      "Step 57\n",
      "Char length: 9843\n",
      "Processing chunk: 281/1018...\n",
      "Step 58\n",
      "Char length: 9999\n",
      "Processing chunk: 286/1018...\n",
      "Process complete! 286/1018 converted.\n",
      "Processing video: 2/2\n",
      "------------------------------------\n",
      "Step 1\n",
      "Char length: 0\n",
      "Processing chunk: 1/1018...\n",
      "Step 2\n",
      "Char length: 19\n",
      "Processing chunk: 6/1018...\n",
      "Step 3\n",
      "Char length: 124\n",
      "Processing chunk: 11/1018...\n",
      "Step 4\n",
      "Char length: 375\n",
      "Processing chunk: 16/1018...\n",
      "Step 5\n",
      "Char length: 596\n",
      "Processing chunk: 21/1018...\n",
      "Step 6\n",
      "Char length: 799\n",
      "Processing chunk: 26/1018...\n",
      "Step 7\n",
      "Char length: 1041\n",
      "Processing chunk: 31/1018...\n",
      "Step 8\n",
      "Char length: 1298\n",
      "Processing chunk: 36/1018...\n",
      "Step 9\n",
      "Char length: 1569\n",
      "Processing chunk: 41/1018...\n",
      "Step 10\n",
      "Char length: 1789\n",
      "Processing chunk: 46/1018...\n",
      "Step 11\n",
      "Char length: 1864\n",
      "Processing chunk: 51/1018...\n",
      "Step 12\n",
      "Char length: 2095\n",
      "Processing chunk: 56/1018...\n",
      "Step 13\n",
      "Char length: 2248\n",
      "Processing chunk: 61/1018...\n",
      "Step 14\n",
      "Char length: 2488\n",
      "Processing chunk: 66/1018...\n",
      "Step 15\n",
      "Char length: 2608\n",
      "Processing chunk: 71/1018...\n",
      "Step 16\n",
      "Char length: 2783\n",
      "Processing chunk: 76/1018...\n",
      "Step 17\n",
      "Char length: 3026\n",
      "Processing chunk: 81/1018...\n",
      "Step 18\n",
      "Char length: 3226\n",
      "Processing chunk: 86/1018...\n",
      "Step 19\n",
      "Char length: 3452\n",
      "Processing chunk: 91/1018...\n",
      "Step 20\n",
      "Char length: 3695\n",
      "Processing chunk: 96/1018...\n",
      "Step 21\n",
      "Char length: 3999\n",
      "Processing chunk: 101/1018...\n",
      "Step 22\n",
      "Char length: 4095\n",
      "Processing chunk: 106/1018...\n",
      "Step 23\n",
      "Char length: 4122\n",
      "Processing chunk: 111/1018...\n",
      "Step 24\n",
      "Char length: 4285\n",
      "Processing chunk: 116/1018...\n",
      "Step 25\n",
      "Char length: 4397\n",
      "Processing chunk: 121/1018...\n",
      "Step 26\n",
      "Char length: 4568\n",
      "Processing chunk: 126/1018...\n",
      "Step 27\n",
      "Char length: 4721\n",
      "Processing chunk: 131/1018...\n",
      "Step 28\n",
      "Char length: 4875\n",
      "Processing chunk: 136/1018...\n",
      "Step 29\n",
      "Char length: 4999\n",
      "Processing chunk: 141/1018...\n",
      "Step 30\n",
      "Char length: 5163\n",
      "Processing chunk: 146/1018...\n",
      "Step 31\n",
      "Char length: 5329\n",
      "Processing chunk: 151/1018...\n",
      "Step 32\n",
      "Char length: 5593\n",
      "Processing chunk: 156/1018...\n",
      "Step 33\n",
      "Char length: 5895\n",
      "Processing chunk: 161/1018...\n",
      "Step 34\n",
      "Char length: 6125\n",
      "Processing chunk: 166/1018...\n",
      "Step 35\n",
      "Char length: 6287\n",
      "Processing chunk: 171/1018...\n",
      "Step 36\n",
      "Char length: 6478\n",
      "Processing chunk: 176/1018...\n",
      "Step 37\n",
      "Char length: 6730\n",
      "Processing chunk: 181/1018...\n",
      "Step 38\n",
      "Char length: 6923\n",
      "Processing chunk: 186/1018...\n",
      "Step 39\n",
      "Char length: 7163\n",
      "Processing chunk: 191/1018...\n",
      "Step 40\n",
      "Char length: 7305\n",
      "Processing chunk: 196/1018...\n",
      "Step 41\n",
      "Char length: 7392\n",
      "Processing chunk: 201/1018...\n",
      "Step 42\n",
      "Char length: 7471\n",
      "Processing chunk: 206/1018...\n",
      "Step 43\n",
      "Char length: 7594\n",
      "Processing chunk: 211/1018...\n",
      "Step 44\n",
      "Char length: 7594\n",
      "Processing chunk: 216/1018...\n",
      "Step 45\n",
      "Char length: 7594\n",
      "Processing chunk: 221/1018...\n",
      "Step 46\n",
      "Char length: 7594\n",
      "Processing chunk: 226/1018...\n",
      "Step 47\n",
      "Char length: 7594\n",
      "Processing chunk: 231/1018...\n",
      "Step 48\n",
      "Char length: 7594\n",
      "Processing chunk: 236/1018...\n",
      "Step 49\n",
      "Char length: 7594\n",
      "Processing chunk: 241/1018...\n",
      "Step 50\n",
      "Char length: 7594\n",
      "Processing chunk: 246/1018...\n",
      "Step 51\n",
      "Char length: 7594\n",
      "Processing chunk: 251/1018...\n",
      "Step 52\n",
      "Char length: 7594\n",
      "Processing chunk: 256/1018...\n",
      "Step 53\n",
      "Char length: 7744\n",
      "Processing chunk: 261/1018...\n",
      "Step 54\n",
      "Char length: 7959\n",
      "Processing chunk: 266/1018...\n",
      "Step 55\n",
      "Char length: 8176\n",
      "Processing chunk: 271/1018...\n",
      "Step 56\n",
      "Char length: 8398\n",
      "Processing chunk: 276/1018...\n",
      "Step 57\n",
      "Char length: 8634\n",
      "Processing chunk: 281/1018...\n",
      "Step 58\n",
      "Char length: 8826\n",
      "Processing chunk: 286/1018...\n",
      "Step 59\n",
      "Char length: 9007\n",
      "Processing chunk: 291/1018...\n",
      "Step 60\n",
      "Char length: 9201\n",
      "Processing chunk: 296/1018...\n",
      "Step 61\n",
      "Char length: 9317\n",
      "Processing chunk: 301/1018...\n",
      "Step 62\n",
      "Char length: 9450\n",
      "Processing chunk: 306/1018...\n",
      "Step 63\n",
      "Char length: 9573\n",
      "Processing chunk: 311/1018...\n",
      "Step 64\n",
      "Char length: 9613\n",
      "Processing chunk: 316/1018...\n",
      "Step 65\n",
      "Char length: 9613\n",
      "Processing chunk: 321/1018...\n",
      "Step 66\n",
      "Char length: 9772\n",
      "Processing chunk: 326/1018...\n",
      "Step 67\n",
      "Char length: 9952\n",
      "Processing chunk: 331/1018...\n",
      "Step 68\n",
      "Char length: 9952\n",
      "Processing chunk: 336/1018...\n",
      "Step 69\n",
      "Char length: 9952\n",
      "Processing chunk: 341/1018...\n",
      "Step 70\n",
      "Char length: 9952\n",
      "Processing chunk: 346/1018...\n",
      "Step 71\n",
      "Char length: 9952\n",
      "Processing chunk: 351/1018...\n",
      "Step 72\n",
      "Char length: 9952\n",
      "Processing chunk: 356/1018...\n",
      "Step 73\n",
      "Char length: 9952\n",
      "Processing chunk: 361/1018...\n",
      "Step 74\n",
      "Char length: 9952\n",
      "Processing chunk: 366/1018...\n",
      "Step 75\n",
      "Char length: 9952\n",
      "Processing chunk: 371/1018...\n",
      "Process complete! 374/1018 converted.\n"
     ]
    }
   ],
   "source": [
    "audio_chunk_to_text(\"data/audio_chunks/\", \"data/text/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performing text similarity matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocess lecture notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Convert ipynb files to html for easier parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/text\\\\lecture3_floating-point.html'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"data/text/lec*\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [os.system(f\"jupyter nbconvert --to html {i}\") for i in glob.glob(\"data/text/lec*\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Read in text using beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_files = glob.glob(\"data/text/*.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipynb_html_text_parser(html_files_list):\n",
    "    \"\"\"\n",
    "    Parses text from jupyter notebook,\n",
    "    HTML files.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    html_files : list\n",
    "        list of relative paths\n",
    "        to the html files.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    text_dict : dictionary\n",
    "        A dictionary of text\n",
    "        where keys are lecture\n",
    "        names and values are \n",
    "        respective texts.\n",
    "    \n",
    "    Example:\n",
    "    ---------\n",
    "    html_files = glob.glob(\"data/text/*.html\")\n",
    "    lecture_texts = ipynb_text_parser(html_files)\n",
    "    \"\"\"\n",
    "    lec_list = []\n",
    "    joined_text_list = []\n",
    "    for file in html_files_list:\n",
    "        # read in file using beautiful soup\n",
    "        soup = BeautifulSoup(open(file), \"html.parser\")\n",
    "        \n",
    "        # get all the text and join\n",
    "        all_text = soup.find_all(\"div\", {\"class\" : \"text_cell_render border-box-sizing rendered_html\"})\n",
    "        joined_text = \" \".join([txt.text for txt in all_text])\n",
    "        \n",
    "        # append lecture name and joined\n",
    "        # text to respective lists.\n",
    "        lecture_name = file.split(\"\\\\\")[1].split('.')[0]\n",
    "        lec_list.append(lecture_name)\n",
    "        joined_text_list.append(joined_text)\n",
    "        \n",
    "    \n",
    "    text_dict = {\"lec_name\" : lec_list, \"lec_text\" : joined_text_list}\n",
    "    \n",
    "    \n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture_texts = ipynb_html_text_parser(html_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Preprocess text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Preprocess lecture notes text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_scrub(string_input):\n",
    "    string_input = str(string_input)\n",
    "    string_input = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', string_input, flags=re.MULTILINE)\n",
    "    string_input = string_input.lower()\n",
    "    string_input = string_input.replace('Â¶', ' ')\n",
    "    string_input = string_input.replace('&', 'and')\n",
    "    string_input = string_input.replace('/', 'or')\n",
    "    string_input = string_input.replace('\\t', ' ')\n",
    "    string_input = string_input.replace('\\n', ' ')\n",
    "    string_input = string_input.translate(str.maketrans(' ', ' ', string.punctuation))\n",
    "\n",
    "    \n",
    "    return string_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lec_notes = pd.DataFrame(lecture_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lec_notes[\"lec_text\"] = df_lec_notes[\"lec_text\"].apply(lambda x: string_scrub(x))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lec_name</th>\n",
       "      <th>lec_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lecture3_floating-point</td>\n",
       "      <td>dsci 572 lecture 3 how to survive in a world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lecture5_neural-networks</td>\n",
       "      <td>dsci 572 lecture 3 how to survive in a world ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lec_name                                           lec_text\n",
       "0   lecture3_floating-point   dsci 572 lecture 3 how to survive in a world ...\n",
       "1  lecture5_neural-networks   dsci 572 lecture 3 how to survive in a world ..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lec_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Preprocess transcribed lecture notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_notes = glob.glob(\"data/text/transc*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/text\\\\transcribed_vid_1.txt', 'data/text\\\\transcribed_vid_2.txt']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribed_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_texts = []\n",
    "vid_names = []\n",
    "for notes in transcribed_notes:\n",
    "    with open(notes, \"r\") as f:\n",
    "        transcribed_text = f.read()\n",
    "    vid_name = notes.split(\"\\\\\")[1].split(\".\")[0].split(\"ed_\")[1]\n",
    "    transcribed_texts.append(transcribed_text)\n",
    "    vid_names.append(vid_name)\n",
    "transcribed_notes_dict = {\"vid_name\" : vid_names, \"transc_text\": transcribed_texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid_name</th>\n",
       "      <th>transc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vid_1</td>\n",
       "      <td>let's get started are you good at the So today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vid_2</td>\n",
       "      <td>all right let's go starting neural networks to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vid_name                                        transc_text\n",
       "0    vid_1  let's get started are you good at the So today...\n",
       "1    vid_2  all right let's go starting neural networks to..."
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transcr_notes = pd.DataFrame(transcribed_notes_dict)\n",
    "df_transcr_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Performing text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [1] https://codeloop.org/python-how-to-convert-recorded-audio-to-text/\n",
    "- [2] https://www.geeksforgeeks.org/audio-processing-using-pydub-and-google-speechrecognition-api/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
