all right let's go starting neural networks today and for the rest of the talking about a recap of the videos get my marker how to talk about what is a neural network cuz there's so clear so far other things like linear regression for exam regression model says the output example of for logistic regression of cycling weighted some of the features and we put it through his entryway side well the prediction is a bunch of FL state what's a neural network it's confusing about it is that it's a multi-step process to the way we actually is Rena do something a bunch of times is actually not dead multiply 10 by a matrix English were going to call biases three. Protected them with our feature vector and we got the outside by here thing is actually going to be a matrix instead of a vector Richmond so it's kind of like linear regression and outputs instead of just one output and for each of those 10 outfits and Sophia 100 features in 10 output and that's what I've tried to write down here is that you have your ex your features you must and you add some intercept and The Intercept is not a vector instead of if we have 10 outputs we have an intercept for each output what's kind of ingredient number one and then we name two it called H which I'll talk about more we do this this weird things can we get out put spit actually do mediate outfits and that's where we have to start thinking differently cuz celebration and then L4 layer you can think of you that information to media thing which isn't actually your prediction yet and in fact you're going to do that a bunch of times and however many times you do that five times you called neural network but doing a bunch of things over and over again to get from your info things we talked about print notation let's let's look at 10 you see what happened so five numbers train example and Hi-5 just squaring that's not a real thing or go just to show that tecnica simplest possible thing of a neural network as simple as this we're going to make it more and more complicated building block so all I've done is I've taken my feature vector 6 because this was a 2 by 5 Matrix five numbers to two numbers there's no meaning to is two numbers and then I did the same thing to them I just so this the production phase of a one layer pretty much exclusively about that. Predict the products Hitler and terminology in other words how you get from it and a fit in scikit-learn technology terminology play witches how does all the optimizer comments about this okay so here's another that's almost the same except now W instead of just being a list of matrices W1 W2 and I've just put and that what is this code doing ignoring the biosphere we can put that back in later so what I'm doing here is I'm just taking my first W in the list playing it by XCX was five numbers 9 * 2 is two numbers and I did this weird age thing to it and that's where we I have a for Loop time is a 1 by 2 Matrix and so I take this I multiply them by that I get a single number to the age thing to it I can run this code two notes Here the fact that they're the same as not a coincidence for example I'll just get an error Scott for light from five numbers to two numbers and then I tried to multiply that's not a valid Matrix so I really have to have some matching shapes here so that the matrix multiplication at work ultimately very confusing about this is that there was that intermediate what went in so we can even print so this Vector went in and this value at the bottom came out but somewhere are lupus halfway done there's this intermediate representation where they were does it called the hidden that's called The Hidden Lair those are the hidden activation that's going to be the sticking point words I think most easy to get confused because we're not media representations are fed five layers we have a bunch of these in we kind of have to think about them and the reason they're called hidden is we see the inputs and receive the output but there at the end bunch of times in the process and it is useful for us which were maybe not used to do yes right 11 * yeah so let me let me so I took w i x x hidden thing that I was talking about and I X so this called this hidden and then I took W-2 and multiplied it by The Hidden a single number app if we do this we should get the same at but six nine Angel all the time with a single-digit time do you pick up we will get to that if you're doing a regression Diamond featuring model selection at the end of the day or just trying to predict yes you're going to run it fishing rare the start of the punchline is going to be if you drink classes you're going to want five numbers to come so you do actually want multiple output desktop the notation that were using access Justice NWS yes director training them for whatever you want to call it w so the weights are now stored in a bunch of and then the output prediction and so this trainings amplex would have been value lion the Neches also like the hidden lair it's just calling activation function and we'll talk about it okay so just a bunch is matrices do not need to be square matrices navigate to all that kind of stuff hidden stated in units hidden neurons activation we are you calling w Wait so that's all good you're going to see these pictures a lot I like these types of pictures three circle is a number so those are three red circles taken together make example and then in this case you have to you trying to go from three numbers to two numbers and you have a hidden lair with four numbers and so you have a 3 by 4 Matrix in here or 4 by 3 and then you have a 4 by 2 Matrix in here and so diagrams is that let's say you have three circles an input and four circles on hidden you're going to have 12 arrows. and that's exactly how many weights you're going to have and you're waiting you have 12 numbers in it and so he's Arrow corresponds to and and what it's saying is that this value is away three values and that's why you have linear regression and the second value is a weighted sum of the 3in Ozark depending on your notation and so you could think of each of these makeup specifying what number to put on training the model doing your optimization corresponds to picking response to picking a number associated with each other a lot of these diagrams they're pretty popular important notes so we can actually have not really used to having most clubfoot smoke just had one output but will defer some of that Wednesday deep learning you probably heard the term it's pretty much the same thing I consider them synonyms Network neural network neural-net those are all the same some acronyms that end in there on that same thing convolutional neural network CNN that's what layers are these that we do to get from the inputs outputs if we do five of those transfer five layer Network sore neurons are active immediate value so you might see someone look at this stag that's for hidden units or that's for hidden neurons that hidden layer has that so just like what we talked about earlier can get very confusing so hit invisible we talked with that activation already referred to the H will talk about that some examples of activation backprop or backpropagation the derivative or the gradient is computed we'll talk about that on Wednesday as well such as life now we're going to do some false questions and read over this first group Okay so budding number 1 raise your country to neural networks can number 2 in text number of parameters is greater than air okay and my three linear regression is a survey neural network nonparametric alright let's bring it back together and do raise your hands for 2 number one turn both regression and Custom is truth for regression we sort of just and for classification we'll talk about that moron number 2 in general for neural networks greater than or equal to the number of feature okay my answer here is true and let's actually go out save this case so here we talked about these 12 parameter is even here hxm I only have three features there in our date or if we got up here here we go in this made-up thing but the number of parameters is 10 so yes in general that is true talk about this in a maybe more nuanced way next week we talked about convolutional neural networks before the that is usually the the number of pizzas will Beatty plus one know the number of parameters will be a lot more this isn't about the minimum that can be is that this is basically linear regression that's why I said greater than or equal to yes with linear regression I would say the number of family resources number because you have that interest okay number 3 linear when is a special case of a neural network that so yes it is and going back up to are you have zero hidden layers just have your inputs going directly to outputs actually if we didn't have AIDS now you're looking at the prediction step of linear regression now if I F I sent this to now we just have a bunch of coefficients like linear regression wood the future is H is not doing anything cuz I said it like this single number so this is the special case where it's just where the activation function is the identity does nothing and one output number for neural networks are nonparametric answer here is false so I'm so supervised one like K nearest Neighbors parameters are has been nothing number of parameters I don't know 20-ish parameters regardless of n then it's parametric cuz we just as opposed to the nonparametric things where we kind before we can talk about grandmothers okay next round I'll give you a what is the optimal height I don't know okay so the end of it number one any neural network with three hidden layers a number two with neural networks we have a potentially large now hyperparameters with neural networks. and number for like linear regression or with neural networks we can interpret each features weight vest measure of the teachers important take a few minutes alright time's up neural network with two change your mind quite a bit since the first Felt So my answer is 